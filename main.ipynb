{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0 ‚Äì CLEAN UP & DOWNLOAD ALL DATASETS INTO THIS FOLDER (run once)\n",
    "# -------------------------------------------------------------------\n",
    "# ‚Ä¢ Deletes old ~/gun-detection-yolo folder\n",
    "# ‚Ä¢ Deletes any prior dataset1/, dataset2/, roboflow_pistols/ in PWD\n",
    "# ‚Ä¢ Downloads Kaggle datasets into ./dataset1 & ./dataset2\n",
    "# ‚Ä¢ Extracts your roboflow_pistols.zip into ./roboflow_pistols\n",
    "\n",
    "# 0-a) install & import\n",
    "import os, shutil, zipfile, glob\n",
    "from pathlib import Path\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# 0-b) remove old root downloads (~/.‚Ä¶/gun-detection-yolo)\n",
    "old_root = Path.home() / \"gun-detection-yolo\"\n",
    "if old_root.exists():\n",
    "    shutil.rmtree(old_root)\n",
    "    print(f\"üóë  Removed old root folder: {old_root}\")\n",
    "\n",
    "# 0-c) remove any leftover folders in PWD\n",
    "pwd = Path.cwd()\n",
    "for name in (\"dataset1\", \"dataset2\", \"roboflow_pistols\"):\n",
    "    p = pwd / name\n",
    "    if p.exists():\n",
    "        if p.is_dir():\n",
    "            shutil.rmtree(p)\n",
    "        else:\n",
    "            p.unlink()\n",
    "        print(f\"üóë  Removed existing: {p}\")\n",
    "\n",
    "# 0-d) authenticate Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# 0-e) download & unzip dataset1 ‚Üí ./dataset1\n",
    "print(\"‚á£ Downloading issaisasank/guns-object-detection ‚Üí dataset1/\")\n",
    "api.dataset_download_files(\n",
    "    \"issaisasank/guns-object-detection\",\n",
    "    path=str(pwd / \"dataset1\"),\n",
    "    unzip=True\n",
    ")\n",
    "print(\"‚úî dataset1 ready at\", pwd / \"dataset1\")\n",
    "\n",
    "# 0-f) download & unzip dataset2 ‚Üí ./dataset2\n",
    "print(\"‚á£ Downloading snehilsanyal/weapon-detection-test ‚Üí dataset2/\")\n",
    "api.dataset_download_files(\n",
    "    \"snehilsanyal/weapon-detection-test\",\n",
    "    path=str(pwd / \"dataset2\"),\n",
    "    unzip=True\n",
    ")\n",
    "print(\"‚úî dataset2 ready at\", pwd / \"dataset2\")\n",
    "\n",
    "# 0-g) extract roboflow_pistols.zip ‚Üí ./roboflow_pistols\n",
    "rf_zip = pwd / \"roboflow_pistols.zip\"\n",
    "if not rf_zip.is_file():\n",
    "    raise FileNotFoundError(f\"‚ùå {rf_zip.name} not found in {pwd}\")\n",
    "print(\"‚á£ Extracting Roboflow pistols ‚Üí roboflow_pistols/\")\n",
    "with zipfile.ZipFile(rf_zip) as zf:\n",
    "    zf.extractall(pwd / \"roboflow_pistols\")\n",
    "print(\"‚úî roboflow_pistols ready at\", pwd / \"roboflow_pistols\")\n",
    "\n",
    "print(\"\\n‚úÖ  Cleanup & downloads complete. Datasets are in:\\n\",\n",
    "      pwd / \"dataset1\", \"\\n\",\n",
    "      pwd / \"dataset2\", \"\\n\",\n",
    "      pwd / \"roboflow_pistols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 ‚Äì merge dataset1, dataset2, roboflow_pistols ‚Üí ./data\n",
    "# ------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "import shutil, random, yaml, sys, itertools\n",
    "\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# 2-a)  üëâ  define roots & auto-detect images / labels\n",
    "roots = {\n",
    "    \"dataset1\": cwd / \"dataset1\",\n",
    "    \"dataset2\": cwd / \"dataset2\",\n",
    "    \"pistols\":  cwd / \"roboflow_pistols\" / \"export\",\n",
    "}\n",
    "for k, p in roots.items():\n",
    "    if not p.exists():\n",
    "        sys.exit(f\"‚ùå {k} root not found at {p}. Check Step 1 output.\")\n",
    "\n",
    "def find_subdirs(root):\n",
    "    \"\"\"return (img_dir, lbl_dir) inside root\"\"\"\n",
    "    # Look for direct images/labels\n",
    "    img = next((d for d in root.rglob(\"*\") if d.name.lower() in (\"images\", \"imgs\")), None)\n",
    "    lbl = next((d for d in root.rglob(\"*\") if d.name.lower().startswith(\"label\")), None)\n",
    "    return img, lbl\n",
    "\n",
    "sources = []\n",
    "for tag, root in roots.items():\n",
    "    img_dir, lbl_dir = find_subdirs(root)\n",
    "    if not (img_dir and lbl_dir):\n",
    "        sys.exit(f\"‚ùå Couldn‚Äôt find images/labels under {root}\")\n",
    "    sources.append((tag, img_dir, lbl_dir))\n",
    "\n",
    "# 2-b)  üëâ  fresh YOLO skeleton\n",
    "yolo_root = cwd / \"data\"\n",
    "if yolo_root.exists():\n",
    "    shutil.rmtree(yolo_root)\n",
    "for split in (\"train\", \"val\"):\n",
    "    (yolo_root / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (yolo_root / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2-c)  üëâ  gather all pairs, prefix names to avoid collisions\n",
    "pairs = []\n",
    "image_exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "for tag, img_dir, lbl_dir in sources:\n",
    "    for img in img_dir.glob(\"*\"):\n",
    "        if img.suffix.lower() not in image_exts:\n",
    "            continue\n",
    "        lbl = lbl_dir / f\"{img.stem}.txt\"\n",
    "        if lbl.exists():\n",
    "            new_stem = f\"{tag}_{img.stem}\"\n",
    "            pairs.append((img, lbl, new_stem))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "cut = int(0.8 * len(pairs))\n",
    "\n",
    "def copy_subset(subset, split):\n",
    "    for img, lbl, stem in subset:\n",
    "        shutil.copy2(img,  yolo_root / split / \"images\" / f\"{stem}{img.suffix.lower()}\")\n",
    "        shutil.copy2(lbl,  yolo_root / split / \"labels\" / f\"{stem}.txt\")\n",
    "\n",
    "copy_subset(pairs[:cut], \"train\")\n",
    "copy_subset(pairs[cut:], \"val\")\n",
    "\n",
    "# 2-d)  üëâ  write data.yaml\n",
    "yaml.safe_dump({\n",
    "    \"train\": str((yolo_root / \"train\" / \"images\").resolve()),\n",
    "    \"val\":   str((yolo_root / \"val\"   / \"images\").resolve()),\n",
    "    \"nc\": 1,\n",
    "    \"names\": [\"gun\"]\n",
    "}, open(yolo_root / \"data.yaml\", \"w\"))\n",
    "\n",
    "print(f\"‚úî Merged {len(pairs)} images  ‚ûú  {len(pairs[:cut])} train / {len(pairs[cut:])} val\")\n",
    "print(\"‚úî YOLO data.yaml written to\", (yolo_root / \"data.yaml\").resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Labels cleaned: all classes remapped to 0, bad rows/files removed.\n"
     ]
    }
   ],
   "source": [
    "# STEP 2.5 ‚Äì CLEAN & UNIFY LABELS ‚Üí single-class 0, drop bad rows\n",
    "# ----------------------------------------------------------------\n",
    "from pathlib import Path\n",
    "\n",
    "for split in (\"train\", \"val\"):\n",
    "    lbl_dir = Path(\"data\") / split / \"labels\"\n",
    "    for txt in lbl_dir.glob(\"*.txt\"):\n",
    "        lines = txt.read_text().splitlines()\n",
    "        clean = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            # need exactly 5 tokens: class + 4 coords\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            # remap any class to 0\n",
    "            _, x, y, w, h = parts[:5]\n",
    "            clean.append(f\"0 {x} {y} {w} {h}\")\n",
    "        if clean:\n",
    "            txt.write_text(\"\\n\".join(clean) + \"\\n\")\n",
    "        else:\n",
    "            # no valid boxes ‚Üí drop the file and its image\n",
    "            txt.unlink()\n",
    "            img = txt.with_suffix(\".jpg\")\n",
    "            if img.exists():\n",
    "                img.unlink()\n",
    "\n",
    "# wipe old label caches so YOLO rebuilds everything\n",
    "for cache in Path(\"data\").rglob(\"labels.cache\"):\n",
    "    cache.unlink(missing_ok=True)\n",
    "\n",
    "print(\"‚úî Labels cleaned: all classes remapped to 0, bad rows/files removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amogharya/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/5_/2xcnn91n409109t8txwvrjn80000gn/T/ipykernel_73710/3879780307.py:17: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n",
      "  \"flip\"      : A.Compose([A.HorizontalFlip(always_apply=True)], bbox_params=bbox_args),\n",
      "/var/folders/5_/2xcnn91n409109t8txwvrjn80000gn/T/ipykernel_73710/3879780307.py:18: UserWarning: Argument(s) 'always_apply' are not valid for transform ToGray\n",
      "  \"gray\"      : A.Compose([A.ToGray(always_apply=True)], bbox_params=bbox_args),\n",
      "/Users/amogharya/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n",
      "/var/folders/5_/2xcnn91n409109t8txwvrjn80000gn/T/ipykernel_73710/3879780307.py:19: UserWarning: Argument(s) 'always_apply' are not valid for transform RGBShift\n",
      "  \"rgbshift\"  : A.Compose([A.RGBShift(25,25,25, always_apply=True)], bbox_params=bbox_args),\n",
      "/var/folders/5_/2xcnn91n409109t8txwvrjn80000gn/T/ipykernel_73710/3879780307.py:20: UserWarning: Argument(s) 'always_apply' are not valid for transform RandomBrightnessContrast\n",
      "  \"bright\"    : A.Compose([A.RandomBrightnessContrast(0.25,0.25, always_apply=True)], bbox_params=bbox_args),\n",
      "/var/folders/5_/2xcnn91n409109t8txwvrjn80000gn/T/ipykernel_73710/3879780307.py:21: UserWarning: Argument(s) 'always_apply' are not valid for transform MotionBlur\n",
      "  \"blur\"      : A.Compose([A.MotionBlur(blur_limit=5, always_apply=True)], bbox_params=bbox_args),\n",
      "/var/folders/5_/2xcnn91n409109t8txwvrjn80000gn/T/ipykernel_73710/3879780307.py:22: UserWarning: Argument(s) 'fog_coef_lower, fog_coef_upper, always_apply' are not valid for transform RandomFog\n",
      "  \"fog\"       : A.Compose([A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3,\n",
      "Augmenting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39167/39167 [31:02<00:00, 21.03it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Augmentation complete ‚Äì created 119238 new images in data/train/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 3 ‚Äì heavy augmentation for robust gun detection\n",
    "# ----------------------------------------------------\n",
    "!pip -q install --upgrade albumentations opencv-python-headless\n",
    "\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "import cv2, uuid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_img_dir   = Path(\"data/train/images\")\n",
    "train_label_dir = Path(\"data/train/labels\")\n",
    "\n",
    "# Bbox helper (YOLO format)\n",
    "bbox_args = A.BboxParams(format=\"yolo\", label_fields=[\"class_ids\"])\n",
    "\n",
    "augs = {\n",
    "    \"flip\"      : A.Compose([A.HorizontalFlip(always_apply=True)], bbox_params=bbox_args),\n",
    "    \"gray\"      : A.Compose([A.ToGray(always_apply=True)], bbox_params=bbox_args),\n",
    "    \"rgbshift\"  : A.Compose([A.RGBShift(25,25,25, always_apply=True)], bbox_params=bbox_args),\n",
    "    \"bright\"    : A.Compose([A.RandomBrightnessContrast(0.25,0.25, always_apply=True)], bbox_params=bbox_args),\n",
    "    \"blur\"      : A.Compose([A.MotionBlur(blur_limit=5, always_apply=True)], bbox_params=bbox_args),\n",
    "    \"fog\"       : A.Compose([A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3,\n",
    "                                         alpha_coef=0.08, always_apply=True)], bbox_params=bbox_args),\n",
    "}\n",
    "\n",
    "def load_yolo(txt):\n",
    "    rows=[]\n",
    "    with open(txt) as f:\n",
    "        for line in f:\n",
    "            parts=line.strip().split()\n",
    "            if len(parts)<5: continue\n",
    "            cls=int(parts[0]); box=list(map(float,parts[1:5]))\n",
    "            rows.append([cls]+box)\n",
    "    return rows\n",
    "\n",
    "def save_yolo(txt,rows):\n",
    "    with open(txt,\"w\") as f:\n",
    "        for r in rows:\n",
    "            cls,*box=r\n",
    "            f.write(f\"{cls} \"+\" \".join(f\"{v:.6f}\" for v in box)+\"\\n\")\n",
    "\n",
    "img_exts={\".jpg\",\".jpeg\",\".png\"}\n",
    "aug_cnt=0\n",
    "\n",
    "for img_path in tqdm(list(train_img_dir.iterdir()), desc=\"Augmenting\"):\n",
    "    if img_path.suffix.lower() not in img_exts: continue\n",
    "    lbl_path=train_label_dir / f\"{img_path.stem}.txt\"\n",
    "    if not lbl_path.exists(): continue\n",
    "\n",
    "    rows=load_yolo(lbl_path)\n",
    "    if not rows: continue\n",
    "\n",
    "    image=cv2.imread(str(img_path))\n",
    "    bboxes=[r[1:] for r in rows]\n",
    "    class_ids=[r[0]   for r in rows]\n",
    "\n",
    "    for tag,aug in augs.items():\n",
    "        res=aug(image=image,bboxes=bboxes,class_ids=class_ids)\n",
    "        if not res[\"bboxes\"]: continue\n",
    "\n",
    "        uid=uuid.uuid4().hex[:6]\n",
    "        new_name=f\"{img_path.stem}_{tag}_{uid}\"\n",
    "        cv2.imwrite(str(train_img_dir/f\"{new_name}{img_path.suffix.lower()}\"), res[\"image\"])\n",
    "\n",
    "        new_rows=[[c,*b] for c,b in zip(res[\"class_ids\"], res[\"bboxes\"])]\n",
    "        save_yolo(train_label_dir/f\"{new_name}.txt\", new_rows)\n",
    "        aug_cnt+=1\n",
    "\n",
    "print(f\"‚úî Augmentation complete ‚Äì created {aug_cnt} new images in {train_img_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üñ•Ô∏è  Device: mps\n",
      "\n",
      "\n",
      "=== Epoch 1/10 ===\n",
      "New https://pypi.org/project/ultralytics/8.3.160 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.156 üöÄ Python-3.12.9 torch-2.7.1 MPS (Apple M4 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=0, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=debug_nano2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/debug_nano2, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=False, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=12, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.1 ms, read: 190.9¬±159.6 MB/s, size: 59.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/amogharya/Documents/gun detection multiple ds/data/train/labels... 139111 images, 261 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139372/139372 [00:26<00:00, 5189.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/amogharya/Documents/gun detection multiple ds/data/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (54.8GB Disk):   9%|‚ñâ         | 13016/139372 [01:07<10:56, 192.41it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 38\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m epoch_start\n\u001b[1;32m     40\u001b[0m mem \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mmemory_allocated() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e9\u001b[39m\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:797\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:227\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:348\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[1;32m    351\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:307\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# Dataloaders\u001b[39;00m\n\u001b[1;32m    306\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(world_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL_RANK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    314\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    315\u001b[0m         rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    316\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    317\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/models/yolo/detect/train.py:84\u001b[0m, in \u001b[0;36mDetectionTrainer.get_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(rank):  \u001b[38;5;66;03m# init dataset *.cache only once if DDP\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m shuffle \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m shuffle:\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/models/yolo/detect/train.py:67\u001b[0m, in \u001b[0;36mDetectionTrainer.build_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mBuild YOLO Dataset for training or validation.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    (Dataset): YOLO dataset object configured for the specified mode.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(de_parallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39mstride\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_yolo_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/data/build.py:117\u001b[0m, in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m dataset \u001b[38;5;241m=\u001b[39m YOLOMultiModalDataset \u001b[38;5;28;01mif\u001b[39;00m multi_modal \u001b[38;5;28;01melse\u001b[39;00m YOLODataset\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# augmentation\u001b[39;49;00m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: probably add a get_hyps_from_cfg function\u001b[39;49;00m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# rectangular batches\u001b[39;49;00m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorstr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfraction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/data/dataset.py:88\u001b[0m, in \u001b[0;36mYOLODataset.__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_segments \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_keypoints), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not use both segments and keypoints.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/data/base.py:143\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_images()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_cache_disk():\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Transforms\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_transforms(hyp\u001b[38;5;241m=\u001b[39mhyp)\n",
      "File \u001b[0;32m~/Documents/gun detection multiple ds/.venv/lib/python3.12/site-packages/ultralytics/data/base.py:273\u001b[0m, in \u001b[0;36mBaseDataset.cache_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 273\u001b[0m         b \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnpy_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_size\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'ram'\u001b[39;00m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mims[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_hw0[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_hw[i] \u001b[38;5;241m=\u001b[39m x  \u001b[38;5;66;03m# im, hw_orig, hw_resized = load_image(self, i)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pathlib.py:840\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, follow_symlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    836\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m    os.stat() does.\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# STEP 4 ‚Äì debug & fast-finish YOLO-v8 nano training with logs\n",
    "# ------------------------------------------------------------\n",
    "from ultralytics import YOLO\n",
    "import torch, multiprocessing as mp, time\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"\\nüñ•Ô∏è  Device: {device}\\n\")\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # tiny backbone\n",
    "\n",
    "# Training config: very small / fast + verbose logging\n",
    "train_cfg = dict(\n",
    "    data         = \"data/data.yaml\",\n",
    "    epochs       = 10,       # quick proof-of-concept\n",
    "    imgsz        = 320,      # smaller resolution\n",
    "    batch        = 4,        # small batch to fit RAM\n",
    "    device       = device,\n",
    "    workers      = mp.cpu_count(),\n",
    "    cache        = \"disk\",   # mmap images, no RAM spike\n",
    "    amp          = True,     # mixed precision on MPS\n",
    "    cos_lr       = True,     # cosine learning-rate decay\n",
    "    close_mosaic = 0,        # disable mosaic\n",
    "    augment      = False,    # no on-the-fly augment\n",
    "    pretrained   = True,\n",
    "    val          = False,    # skip per-epoch validation\n",
    "    verbose      = True,     # force detailed logs\n",
    "    plots        = False,    # skip saving plots\n",
    "    save_period  = 1,        # save weights every epoch\n",
    "    project      = \"runs\",\n",
    "    name         = \"debug_nano\",\n",
    ")\n",
    "\n",
    "# Run training with per-epoch timing\n",
    "start_total = time.time()\n",
    "for epoch in range(1, train_cfg[\"epochs\"] + 1):\n",
    "    print(f\"\\n=== Epoch {epoch}/{train_cfg['epochs']} ===\")\n",
    "    epoch_start = time.time()\n",
    "    model.train(**{**train_cfg, \"epochs\":1, \"resume\": epoch>1})\n",
    "    elapsed = time.time() - epoch_start\n",
    "    mem = torch.backends.mps.memory_allocated() / 1e9\n",
    "    print(f\"‚è±Ô∏è  Epoch {epoch} done in {elapsed:.1f}s ‚Äì MPS mem: {mem:.2f} GB\")\n",
    "\n",
    "print(f\"\\nüèÅ All epochs completed in {(time.time()-start_total)/60:.1f} min\")\n",
    "print(\"‚úî  Weights & logs in runs/debug_nano/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
